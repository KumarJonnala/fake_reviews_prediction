{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/kumar/fake_reviews_prediction/Datasets/fake_reviews_dataset.csv\"  # Example: 'data/reviews.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Full Dataset:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = {'category', 'rating', 'label', 'text_'}\n",
    "if not required_columns.issubset(df.columns):\n",
    "    raise ValueError(f\"Missing columns! Expected {required_columns}, found {set(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = df[['category']].copy()\n",
    "rating_df = df[['rating']].copy()\n",
    "label_df = df[['label']].copy()\n",
    "text_df = df[['text_']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_\n",
       "0  Love this!  Well made, sturdy, and very comfor...\n",
       "1  love it, a great upgrade from the original.  I...\n",
       "2  This pillow saved my back. I love the look and...\n",
       "3  Missing information on how to use it, but it i...\n",
       "4  Very nice set. Good quality. We have had the s..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nText DataFrame:\")\n",
    "display(text_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "model = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query the local LLM server\n",
    "\n",
    "def query_llm(prompt: str, model: str = model) -> str: # arguments promt and model\n",
    "    # Send a request to the local LLM server, stream set to Falsefor single responce\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",  \n",
    "        json={\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \n",
      "Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty\n",
      "Original\n"
     ]
    }
   ],
   "source": [
    "# Model Response with DeepSeek r1 1.5b\n",
    "text=str(text_df['text_'].iloc[[0]].values[0])\n",
    "print(\"Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \\n\"+text)\n",
    "print(query_llm(\"Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \\n\"+text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \n",
      "Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty\n",
      "Original\n"
     ]
    }
   ],
   "source": [
    "# Model Response with Gemma 3\n",
    "\n",
    "text=str(text_df['text_'].iloc[[0]].values[0])\n",
    "print(\"Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \\n\"+text)\n",
    "print(query_llm(\"Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \\n\"+text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"qwen2:0.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \n",
      "Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty\n",
      "Original\n"
     ]
    }
   ],
   "source": [
    "# Model Response with qwen2:0.5b\n",
    "\n",
    "text=str(text_df['text_'].iloc[[0]].values[0])\n",
    "print(\"Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \\n\"+text)\n",
    "print(query_llm(\"Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \\n\"+text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"qwen2:0.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemma3:4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.concat([text_df.reset_index(drop=True),\n",
    "                       label_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#merged_df = merged_df.fillna(\"\")\n",
    "\n",
    "sample_df = merged_df.head(1000).copy()\n",
    "#sample_df = text_df.head(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(prompt: str, model: str = model) -> str:\n",
    "    \"\"\"Send text to Ollama model and return response.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\"model\": model, \"prompt\": str(prompt), \"stream\": False}\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json().get(\"response\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error for prompt: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name :llama3.2:1b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying LLM: 100%|██████████| 1000/1000 [03:36<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished! Results saved as CSV file'\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Response",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6a05c844-7e8a-4ef6-a048-077d22a0da45",
       "rows": [
        [
         "0",
         "Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty",
         "CG",
         "Computer-generated review."
        ],
        [
         "1",
         "love it, a great upgrade from the original.  I've had mine for a couple of years",
         "CG",
         "Original review."
        ],
        [
         "2",
         "This pillow saved my back. I love the look and feel of this pillow.",
         "CG",
         "Original review."
        ],
        [
         "3",
         "Missing information on how to use it, but it is a great product for the price!  I",
         "CG",
         "Original review"
        ],
        [
         "4",
         "Very nice set. Good quality. We have had the set for two months now and have not been",
         "CG",
         "Computer-generated review"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>CG</td>\n",
       "      <td>Computer-generated review.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>CG</td>\n",
       "      <td>Original review.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>CG</td>\n",
       "      <td>Original review.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>CG</td>\n",
       "      <td>Original review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>CG</td>\n",
       "      <td>Computer-generated review</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...    CG   \n",
       "1  love it, a great upgrade from the original.  I...    CG   \n",
       "2  This pillow saved my back. I love the look and...    CG   \n",
       "3  Missing information on how to use it, but it i...    CG   \n",
       "4  Very nice set. Good quality. We have had the s...    CG   \n",
       "\n",
       "                     Response  \n",
       "0  Computer-generated review.  \n",
       "1            Original review.  \n",
       "2            Original review.  \n",
       "3             Original review  \n",
       "4   Computer-generated review  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "print(\"Model name :\"+model)\n",
    "for i, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Querying LLM\"):\n",
    "    text = str(row.get('text_', row.get('text', '')))  # supports both 'text_' and 'text'\n",
    "    label = row.get('label', '')\n",
    "    response = query_llm(\"Classify the sentiment of below statement into Original review or Computer-generated review. Answer in one word \\n\"+text)\n",
    "    results.append({\"text\": text, \"label\": label, \"Response\": response})\n",
    "output_df = pd.DataFrame(results)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "output_df.to_csv(\"llm_output_llama3_1000.csv\", index=False)\n",
    "#output_df.to_csv(\"llm_output.csv\", index=False)\n",
    "#output_df.to_csv(\"llm_output.csv\", index=False)\n",
    "\n",
    "print(\"✅ Finished! Results saved as CSV file'\")\n",
    "display(output_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.52      0.30      0.38        50\n",
      "          OR       0.46      0.68      0.55        44\n",
      "\n",
      "    accuracy                           0.48        94\n",
      "   macro avg       0.49      0.49      0.47        94\n",
      "weighted avg       0.49      0.48      0.46        94\n",
      "\n",
      "\n",
      " Saved cleaned file as 'llm_qwen_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Load your CSV ---\n",
    "df = pd.read_csv(\"D:\\OVGU _Saurabh\\SEM 3\\Review Project\\Code\\Models\\llm_output_qwen_100.csv\")\n",
    "\n",
    "# --- Clean and standardize text ---\n",
    "df['label'] = df['label'].astype(str).str.strip().str.upper()\n",
    "df['Response'] = df['Response'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# --- Apply your rules ---\n",
    "def normalize_response(resp: str) -> str:\n",
    "    if \"computer\" in resp:\n",
    "        return \"CG\"\n",
    "    elif \"original\" in resp:\n",
    "        return \"OR\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "df['Predicted'] = df['Response'].apply(normalize_response)\n",
    "\n",
    "# --- Filter out UNKNOWN for accuracy ---\n",
    "valid_df = df[df['Predicted'] != \"UNKNOWN\"]\n",
    "\n",
    "accuracy = accuracy_score(valid_df['label'], valid_df['Predicted'])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(valid_df['label'], valid_df['Predicted']))\n",
    "\n",
    "df.to_csv(\"llm_qwen_cleaned.csv\", index=False)\n",
    "print(\"\\n Saved cleaned file as 'llm_qwen_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.70      0.04      0.08       519\n",
      "          OR       0.49      0.98      0.65       481\n",
      "\n",
      "    accuracy                           0.49      1000\n",
      "   macro avg       0.59      0.51      0.37      1000\n",
      "weighted avg       0.60      0.49      0.36      1000\n",
      "\n",
      "\n",
      " Saved cleaned file as 'llm_gemma3_cleaned_1000.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Load your CSV ---\n",
    "df = pd.read_csv(\"D:\\OVGU _Saurabh\\SEM 3\\Review Project\\Code\\Models\\llm_output_gemma3_1000.csv\")\n",
    "\n",
    "df['label'] = df['label'].astype(str).str.strip().str.upper()\n",
    "df['Response'] = df['Response'].astype(str).str.strip().str.lower()\n",
    "\n",
    "def normalize_response(resp: str) -> str:\n",
    "    if \"computer\" in resp:\n",
    "        return \"CG\"\n",
    "    elif \"original\" in resp:\n",
    "        return \"OR\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "df['Predicted'] = df['Response'].apply(normalize_response)\n",
    "\n",
    "valid_df = df[df['Predicted'] != \"UNKNOWN\"]\n",
    "\n",
    "accuracy = accuracy_score(valid_df['label'], valid_df['Predicted'])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(valid_df['label'], valid_df['Predicted']))\n",
    "\n",
    "\n",
    "df.to_csv(\"llm_gemma3_cleaned_1000.csv\", index=False)\n",
    "print(\"\\n Saved cleaned file as 'llm_gemma3_cleaned_1000.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.60      0.22      0.32        55\n",
      "          OR       0.46      0.82      0.59        45\n",
      "\n",
      "    accuracy                           0.49       100\n",
      "   macro avg       0.53      0.52      0.46       100\n",
      "weighted avg       0.54      0.49      0.44       100\n",
      "\n",
      "\n",
      " Saved cleaned file as 'llm_deepseek_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Load your CSV ---\n",
    "df = pd.read_csv(\"D:\\OVGU _Saurabh\\SEM 3\\Review Project\\Code\\Models\\llm_output_deepseek_100.csv\")\n",
    "\n",
    "df['label'] = df['label'].astype(str).str.strip().str.upper()\n",
    "df['Response'] = df['Response'].astype(str).str.strip().str.lower()\n",
    "\n",
    "def normalize_response(resp: str) -> str:\n",
    "    if \"computer\" in resp:\n",
    "        return \"CG\"\n",
    "    elif \"original\" in resp:\n",
    "        return \"OR\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "df['Predicted'] = df['Response'].apply(normalize_response)\n",
    "\n",
    "valid_df = df[df['Predicted'] != \"UNKNOWN\"]\n",
    "\n",
    "accuracy = accuracy_score(valid_df['label'], valid_df['Predicted'])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(valid_df['label'], valid_df['Predicted']))\n",
    "\n",
    "df.to_csv(\"llm_deepseek_cleaned.csv\", index=False)\n",
    "print(\"\\n Saved cleaned file as 'llm_deepseek_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.51      0.09      0.15       518\n",
      "          OR       0.48      0.91      0.63       481\n",
      "\n",
      "    accuracy                           0.48       999\n",
      "   macro avg       0.50      0.50      0.39       999\n",
      "weighted avg       0.50      0.48      0.38       999\n",
      "\n",
      "\n",
      " Saved cleaned file as 'llm_llama3_1000_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Load your CSV ---\n",
    "df = pd.read_csv(\"/Users/kumar/fake_reviews_prediction/Models/llm_output_llama3_1000.csv\")\n",
    "\n",
    "df['label'] = df['label'].astype(str).str.strip().str.upper()\n",
    "df['Response'] = df['Response'].astype(str).str.strip().str.lower()\n",
    "\n",
    "def normalize_response(resp: str) -> str:\n",
    "    if \"computer\" in resp:\n",
    "        return \"CG\"\n",
    "    elif \"original\" in resp:\n",
    "        return \"OR\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "df['Predicted'] = df['Response'].apply(normalize_response)\n",
    "\n",
    "valid_df = df[df['Predicted'] != \"UNKNOWN\"]\n",
    "\n",
    "accuracy = accuracy_score(valid_df['label'], valid_df['Predicted'])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(valid_df['label'], valid_df['Predicted']))\n",
    "\n",
    "df.to_csv(\"llm_llama3_1000_cleaned.csv\", index=False)\n",
    "print(\"\\n Saved cleaned file as 'llm_llama3_1000_cleaned.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
